# =============================================================================
# AcePlus Backend Environment Configuration
# =============================================================================
# 
# This file contains all the environment variables needed to configure your
# AcePlus backend application. Copy this file to .env and fill in your values.
#
# IMPORTANT: Never commit your actual .env file to version control!
# =============================================================================

# =============================================================================  
# PROVIDER CONFIGURATION
# =============================================================================
# 
# Step 1: List all providers you want to enable
# Format: PROVIDERS=["PROVIDER1","PROVIDER2","PROVIDER3"]
# Note: Use UPPERCASE names without underscores (e.g., GEMINI, not gemini or GEMINI_AI)
#
PROVIDERS=["CEREBRAS","GEMINI"]

# Step 2: Configure each provider with the following pattern:
# PROVIDER_API_KEY=your_api_key_here           # Required
# PROVIDER_BASE_URL=https://api.provider.com   # Required  
# PROVIDER_MODELS=["model1","model2"]          # Required
#
# For multiple API keys per provider, add:
# PROVIDER_API_KEY_2=your_second_api_key
# PROVIDER_BASE_URL_2=https://api.provider.com
# PROVIDER_API_KEY_3=your_third_api_key
# PROVIDER_BASE_URL_3=https://api.provider.com
# (All keys share the same PROVIDER_MODELS configuration)

# -----------------------------------------------------------------------------
# Cerebras Configuration
# -----------------------------------------------------------------------------
CEREBRAS_API_KEY=your_cerebras_api_key_here
CEREBRAS_BASE_URL=https://api.cerebras.ai/v1

# -----------------------------------------------------------------------------
# Google Gemini Configuration
# -----------------------------------------------------------------------------
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta/openai/

# Optional: Additional Gemini API keys for load balancing
# GEMINI_API_KEY_2=your_second_gemini_api_key
# GEMINI_BASE_URL_2=https://generativelanguage.googleapis.com/v1beta/openai/

# -----------------------------------------------------------------------------
# Example: OpenAI Configuration (uncomment and configure if needed)
# -----------------------------------------------------------------------------
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODELS=["gpt-4","gpt-3.5-turbo","gpt-4-turbo"]

# -----------------------------------------------------------------------------
# Example: Claude Configuration (uncomment and configure if needed)
# -----------------------------------------------------------------------------
# CLAUDE_API_KEY=your_claude_api_key_here
# CLAUDE_BASE_URL=https://api.anthropic.com
# CLAUDE_MODELS=["claude-3-opus","claude-3-sonnet","claude-3-haiku"]

# =============================================================================
# MODEL ASSIGNMENT CONFIGURATION
# =============================================================================
# 
# Assign specific providers and models for different use cases
# Use the exact PROVIDER NAME from your PROVIDERS list above
#

# Image Analysis Models Configuration
IMAGE_MODELS=["GEMINI/gemini-exp-1206"]

# Performance/Speed Optimized Models Configuration
PERFORMANCE_MODELS=["GEMINI/gemini-2.0-flash-exp"]

# Hint Models Configuration
HINT_MODELS=["GEMINI/gemini-2.0-flash-exp"]

# Solution Models Configuration
SOLUTION_MODELS=["GEMINI/gemini-2.0-flash-exp"]

# Performance Analysis Models Configuration
PERFORMANCE_ANALYSIS_MODELS=["GEMINI/gemini-2.0-flash-exp", "GEMINI/gemini-2.5-flash-exp"]

# PDF Processing Models Configuration
PROCESSING_MODELS=["GEMINI/gemini-2.5-flash-exp"]

# Question Generation Models Configuration  
ADDITIONAL_QUESTIONS_MODELS=["GEMINI/gemini-2.5-flash-exp"]

# Validation Models Configuration
VALIDATION_MODELS=["CEREBRAS/llama-3.3-70b", "GEMINI/gemini-2.5-flash-exp", "GROQ/llama-3.3-70b-versatile"]

# Verification Models Configuration
VERIFICATION_MODELS=["CEREBRAS/llama-3.3-70b", "GEMINI/gemini-2.0-flash", "GEMINI/gemini-2.5-flash-exp", "GEMINI/gemini-2.5-flash-lite-preview-06-17"]

#formatter model configuration

FORMATTING_MODELS=["CEREBRAS/llama-3.3-70b", "GEMINI/gemini-2.5-flash-exp", "GEMINI/gemini-2.5-flash-lite-preview-06-17"]

# Fallback/Alternate Models Configuration
ALTERNATE_MODELS=["GEMINI/gemini-exp-1206"]

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# -----------------------------------------------------------------------------
# MongoDB Configuration
# -------------------
# Connection string format: mongodb+srv://<username>:<password>@<cluster>.mongodb.net/?appName=<app>
MONGODB_URI=your_mongodb_connection_string
MONGODB_DB_CLASS9=student_database        # Database name for class 9
MONGODB_DB_CLASS10=student_database_class10  # Database name for class 10

# Flask Configuration
# -----------------
FLASK_SECRET_KEY=your_secret_key          # Required for JWT and session security
FLASK_PORT=9027                           # Port to run the Flask server on
FLASK_HOST=0.0.0.0                        # Host to bind the server to
FLASK_DEBUG=False                         # Set to True for development

# Upload Configuration
# ------------------
MAX_CONTENT_LENGTH=16777216               # Maximum file upload size in bytes (16MB)
UPLOAD_FOLDER=uploads                     # Folder to store uploaded files
ALLOWED_EXTENSIONS=png,jpg,jpeg      # Comma-separated list of allowed file extensions
